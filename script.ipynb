{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "workers = pd.read_csv('workers.csv')\n",
    "job_locations = pd.read_csv('job_locations.csv')\n",
    "\n",
    "# Example preprocessing steps\n",
    "# Convert categorical variables to numerical ones (e.g., skill set, language proficiency)\n",
    "workers['skill_set'] = workers['skill_set'].astype('category').cat.codes\n",
    "workers['language_proficiency'] = workers['language_proficiency'].astype('category').cat.codes\n",
    "job_locations['required_skill_set'] = job_locations['required_skill_set'].astype('category').cat.codes\n",
    "# # Calculate proximity (assuming lat/lon data for simplicity)\n",
    "# def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "#     from geopy.distance import geodesic\n",
    "#     return geodesic((lat1, lon1), (lat2, lon2)).km\n",
    "\n",
    "# job_locations['proximity'] = job_locations.apply(\n",
    "#     lambda row: calculate_distance(row['lat'], row['lon'], workers['lat'], workers['lon']), axis=1\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   worker_id  job_location_id  skill_match  cost\n",
      "0          1              101         True    25\n",
      "1          2              102         True    30\n",
      "2          3              103         True    28\n",
      "3          4              104         True    35\n",
      "4          5              105         True    26\n"
     ]
    }
   ],
   "source": [
    "# Create features for matching\n",
    "features = pd.DataFrame()\n",
    "features['worker_id'] = workers['worker_id']\n",
    "features['job_location_id'] = job_locations['job_location_id']\n",
    "features['skill_match'] = (workers['skill_set'] == job_locations['required_skill_set']).astype(int)\n",
    "# features['proximity'] = job_locations['proximity']\n",
    "features['cost'] = workers['wage_rate']\n",
    "print(features)\n",
    "\n",
    "# You can add more features as necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume you have a label indicating successful matches\n",
    "# features['label'] = ... # Your label data here\n",
    "\n",
    "# Split data\n",
    "X = features.drop('skill_match', axis=1)\n",
    "y = features['skill_match']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_productivity(experience_level, past_performance, health_status):\n",
    "    # Assign numeric values to experience levels and health statuses\n",
    "    experience_value = {'Beginner': 0.8, 'Intermediate': 1.0, 'Advanced': 1.2}\n",
    "    health_value = {'Healthy': 1.0, 'Minor Issues': 0.8, 'Major Issues': 0.5}\n",
    "    \n",
    "    # Calculate productivity score\n",
    "    score = (experience_value[experience_level] * past_performance * health_value[health_status])\n",
    "    return round(score, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate workers data (generated_workers.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Define the number of records\n",
    "num_records = 2000\n",
    "\n",
    "# Predefined lists for random choices\n",
    "skill_sets = ['Plumbing', 'Electrical', 'Carpentry', 'Painting', 'Landscaping', 'HVAC', 'Roofing', 'Drywall', 'Flooring', 'Heavy Machinery Operation']\n",
    "experience_levels = ['Beginner', 'Intermediate', 'Advanced']\n",
    "health_statuses = ['Healthy', 'Minor Issues', 'Major Issues']\n",
    "job_sites = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "# training_statuses = ['Completed', 'In Progress', 'Not Started']\n",
    "# work_conditions = ['Indoor', 'Outdoor', 'High-altitude', 'Underwater']\n",
    "\n",
    "def generate_record(worker_id):\n",
    "    experience_level = random.choice(experience_levels)\n",
    "    past_performance = random.randint(1, 10)  # Assuming 1 to 10 scale\n",
    "    health_status = random.choice(health_statuses)\n",
    "    \n",
    "    return {\n",
    "        'worker_id': worker_id,\n",
    "        'name': fake.name(),\n",
    "        'skill_set': random.choice(skill_sets),\n",
    "        'experience_level': experience_level,\n",
    "        'availability': random.choice(['Available', 'Unavailable']),\n",
    "        'health_status': health_status,\n",
    "        'past_performance': past_performance,\n",
    "        # 'wage_rate': round(random.uniform(15, 50), 2),  # Assuming hourly rate in dollars\n",
    "        # 'job_sites': random.choice(job_sites),  # New column for job sites\n",
    "        'productivity_score': calculate_productivity(experience_level, past_performance, health_status)  # New column for productivity score\n",
    "    }\n",
    "\n",
    "# Generate records\n",
    "records = [generate_record(i+1) for i in range(num_records)]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('generated_workers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "# Assuming skill_set is a list of skills you want to use as keys\n",
    "skill_set = ['Plumbing', 'Electrical', 'Carpentry', 'Painting', 'Landscaping', 'HVAC', 'Roofing', 'Drywall', 'Flooring', 'Heavy Machinery Operation']\n",
    "\n",
    "# Generating a dictionary with skills as keys and random days (1-100) as values\n",
    "skill_days_dict = {skill: random.randint(1, 100) for skill in skill_set}\n",
    "\n",
    "job_sites = [chr(i) for i in range(ord('A'), ord('J')+1)]  # Generates list ['A', 'B', ..., 'J']\n",
    "safety_requirements = ['low', 'med', 'high']\n",
    "\n",
    "import statistics\n",
    "\n",
    "records = []\n",
    "for job_site in job_sites:\n",
    "    unique_skill_days_dict = {skill: random.randint(1, 100) for skill in skill_set}\n",
    "    skills_list = [{'skill': skill, 'days': days} for skill, days in unique_skill_days_dict.items()]\n",
    "    \n",
    "    mean_days = statistics.mean([skill['days'] for skill in skills_list])\n",
    "    # Calculate the percentage of work done\n",
    "    percentage_work_done = 100 - mean_days\n",
    "    \n",
    "    record = {\n",
    "        'job_site': job_site,\n",
    "        'skill_days_dict': skills_list,  # This will now be a unique list of dictionaries for each job site\n",
    "        'safety_requirements': random.choice(safety_requirements),\n",
    "        'percentage_work_done': percentage_work_done  # New field showing the percentage of work done\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "with open('job_site.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Update the header row to include the new column\n",
    "    writer.writerow(['job_site', 'skill_days_dict', 'safety_requirements', 'percentage_work_done'])\n",
    "    for record in records:\n",
    "        # Converting the list of dictionaries to a string for CSV writing\n",
    "        skill_days_str = '; '.join([f\"{skill['skill']}: {skill['days']}\" for skill in record['skill_days_dict']])\n",
    "        # Write the new field to the CSV\n",
    "        writer.writerow([record['job_site'], skill_days_str, record['safety_requirements'], f\"{record['percentage_work_done']:.2f}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create a directory to store the ranks folder\n",
    "os.makedirs('ranks', exist_ok=True)\n",
    "\n",
    "# Read the generated workers data from the CSV file\n",
    "df = pd.read_csv('generated_workers.csv')\n",
    "\n",
    "# Group the workers by skill set\n",
    "grouped = df.groupby('skill_set')\n",
    "\n",
    "for skill_set, group in grouped:\n",
    "    # Filter the group for available workers before ranking\n",
    "    available_group = group[group['availability'] == 'Available']\n",
    "    \n",
    "    # Sort the available group by productivity score in descending order\n",
    "    ranked_group = available_group.sort_values('productivity_score', ascending=False)\n",
    "    \n",
    "    # Create a separate folder for each skill set\n",
    "    folder_path = os.path.join('ranks', skill_set)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    # Save the ranked group to a CSV file in the corresponding folder\n",
    "    file_path = os.path.join(folder_path, 'skill_rank.csv')\n",
    "    ranked_group.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Job Site ID                      skill  Percentage\n",
      "0            I                   Plumbing    6.630582\n",
      "1            I                 Electrical   12.043302\n",
      "2            I                  Carpentry    7.713126\n",
      "3            I                   Painting   12.178620\n",
      "4            I                Landscaping   13.125846\n",
      "..         ...                        ...         ...\n",
      "95           A                       HVAC   15.789474\n",
      "96           A                    Roofing    0.250627\n",
      "97           A                    Drywall   22.807018\n",
      "98           A                   Flooring   23.057644\n",
      "99           A  Heavy Machinery Operation    0.751880\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_job_sites = pd.read_csv('job_site.csv')\n",
    "ranked_job_sites = df_job_sites.sort_values('percentage_work_done', ascending=True)\n",
    "\n",
    "# Initialize a list to store job site ID, skill, and percentage\n",
    "skill_percentages = []\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in ranked_job_sites.iterrows():\n",
    "    # Split the string by ';' to get individual skill-day pairs\n",
    "    skill_days_pairs = row['skill_days_dict'].split(';')\n",
    "    \n",
    "    # Initialize a variable to store total days for the current job site\n",
    "    total_days_current_job_site = sum(int(pair.split(':')[1].strip()) for pair in skill_days_pairs)\n",
    "    \n",
    "    # Iterate through the pairs again to calculate the percentage for each skill\n",
    "    for pair in skill_days_pairs:\n",
    "        skill, days = pair.split(':')\n",
    "        skill = skill.strip()\n",
    "        days = int(days.strip())\n",
    "        \n",
    "        # Calculate the percentage of days for the current skill\n",
    "        skill_percentage = (days / total_days_current_job_site) * 100 if total_days_current_job_site > 0 else 0\n",
    "        \n",
    "        # Append the job site ID (or name), skill, and percentage to the list\n",
    "        skill_percentages.append([row['job_site'], skill, skill_percentage])  # Assuming there's a 'job_site_id' column\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df_skill_percentages = pd.DataFrame(skill_percentages, columns=['Job Site ID', 'skill', 'Percentage'])\n",
    "\n",
    "print(df_skill_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Job Site ID      skill  Percentage\n",
      "0            J  Carpentry   15.473888\n",
      "1            A  Carpentry   14.786967\n",
      "2            B  Carpentry   13.718412\n",
      "3            G  Carpentry   11.669659\n",
      "4            E  Carpentry   10.924370\n",
      "..         ...        ...         ...\n",
      "95           I    Roofing   10.825440\n",
      "96           C    Roofing    7.425743\n",
      "97           H    Roofing    6.688963\n",
      "98           D    Roofing    4.262877\n",
      "99           A    Roofing    0.250627\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_764/3720486569.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_skills_sorted = df_skill_percentages.groupby('skill').apply(lambda x: x.sort_values('Percentage', ascending=False))\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Skill' and then apply sorting within each group by 'Percentage'\n",
    "df_skills_sorted = df_skill_percentages.groupby('skill').apply(lambda x: x.sort_values('Percentage', ascending=False))\n",
    "\n",
    "# Reset index to clean up the DataFrame\n",
    "df_skills_sorted = df_skills_sorted.reset_index(drop=True)\n",
    "\n",
    "print(df_skills_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Job Site ID', 'skill', 'Percentage'], dtype='object')\n",
      "{762: 'J', 1733: 'J', 983: 'J', 851: 'J', 501: 'J', 382: 'J', 1955: 'J', 958: 'J', 1214: 'J', 1375: 'J', 919: 'J', 859: 'J', 867: 'J', 801: 'J', 254: 'J', 1829: 'J', 1000: 'J', 1302: 'J', 256: 'J', 999: 'J', 1972: 'J', 834: 'J', 1400: 'J', 265: 'J', 1034: 'J', 1571: 'J', 1624: 'J', 1456: 'J', 565: 'J', 165: 'J', 1758: 'J', 1708: 'J', 362: 'J', 700: 'J', 267: 'J', 368: 'J', 1336: 'J', 1553: 'J', 892: 'J', 1985: 'J', 916: 'J', 1788: 'J', 386: 'J', 824: 'J', 1472: 'J', 713: 'J', 1334: 'J', 1500: 'J', 1976: 'J', 1907: 'J', 839: 'J', 1346: 'J', 1593: 'J', 1716: 'J', 261: 'J', 1496: 'J', 1255: 'J', 1055: 'J', 490: 'J', 560: 'J', 1536: 'J', 1740: 'J', 404: 'J', 566: 'J', 464: 'J', 571: 'J', 106: 'J', 955: 'J', 183: 'J', 1530: 'J', 1015: 'J', 1157: 'J', 191: 'J', 271: 'J', 909: 'J', 630: 'J', 1121: 'J', 1455: 'J', 587: 'J', 1878: 'J', 1897: 'J', 428: 'J', 300: 'J', 46: 'J', 1951: 'J', 456: 'J', 844: 'J', 409: 'A', 335: 'A', 1614: 'A', 820: 'A', 1005: 'A', 1231: 'A', 633: 'A', 1236: 'A', 1423: 'A', 1516: 'A', 662: 'A', 1238: 'A', 289: 'A', 155: 'A', 884: 'A', 1655: 'A', 69: 'A', 139: 'A', 989: 'A', 30: 'A', 552: 'A', 1210: 'A', 1118: 'A', 1490: 'A', 1147: 'A', 1782: 'A', 1678: 'A', 553: 'A', 1862: 'A', 1129: 'A', 448: 'A', 1306: 'A', 992: 'A', 870: 'A', 1799: 'A', 1025: 'A', 513: 'A', 615: 'A', 1069: 'A', 74: 'A', 1804: 'A', 415: 'A', 1612: 'A', 207: 'A', 227: 'A', 393: 'A', 1563: 'A', 1998: 'A', 394: 'A', 1682: 'A', 812: 'A', 325: 'A', 1295: 'A', 1953: 'A', 252: 'A', 1589: 'A', 1292: 'A', 138: 'A', 86: 'A', 738: 'A', 741: 'A', 1011: 'A', 548: 'A', 830: 'A', 1669: 'A', 1787: 'A', 1802: 'A', 314: 'A', 1603: 'A', 276: 'A', 1942: 'A', 998: 'A', 173: 'A', 807: 'A', 374: 'A', 1047: 'A', 1771: 'A', 1795: 'A', 44: 'A', 1848: 'A', 175: 'A', 25: 'A', 225: 'A', 1252: 'A', 1990: 'A', 959: 'A', 1211: 'A', 1420: 'A', 976: 'A', 529: 'A', 1641: 'A', 1562: 'B', 76: 'B', 63: 'B', 1098: 'B', 1619: 'B', 496: 'B', 1441: 'B', 356: 'B', 1992: 'B', 1966: 'B', 240: 'B', 680: 'B', 754: 'B', 836: 'B', 751: 'B', 1556: 'B', 768: 'B', 436: 'B', 929: 'B', 92: 'B', 1606: 'B', 634: 'B', 476: 'B', 1703: 'B', 720: 'B', 668: 'B', 821: 'B', 266: 'B', 691: 'B', 554: 'B', 1064: 'B', 872: 'B', 1216: 'B', 672: 'B', 424: 'B', 1689: 'B', 1597: 'B', 329: 'B', 2000: 'B', 373: 'B', 1272: 'B', 1748: 'B', 596: 'B', 629: 'B', 255: 'B', 141: 'B', 28: 'B', 1541: 'B', 1713: 'B', 185: 'B', 1620: 'B', 1752: 'B', 1618: 'B', 1695: 'B', 710: 'B', 1772: 'B', 15: 'B', 840: 'B', 168: 'B', 677: 'B', 1705: 'B', 538: 'B', 1041: 'B', 1271: 'B', 1494: 'B', 1547: 'B', 638: 'B', 495: 'B', 1495: 'B', 689: 'B', 228: 'B', 1057: 'B', 154: 'B', 1999: 'B', 1028: 'B', 740: 'B', 1744: 'B', 316: 'B', 628: 'B', 1523: 'B', 299: 'B', 1237: 'B', 709: 'B', 1332: 'B', 1902: 'B', 35: 'B', 287: 'B', 452: 'B', 933: 'B', 1393: 'B', 530: 'G', 1277: 'G', 323: 'G', 1365: 'G', 412: 'G', 729: 'G', 979: 'G', 396: 'G', 477: 'G', 1399: 'G', 1508: 'G', 437: 'G', 935: 'G', 197: 'G', 543: 'G', 1251: 'G', 334: 'G', 962: 'G', 1470: 'G', 646: 'G', 1895: 'G', 1997: 'G', 170: 'G', 932: 'G', 1087: 'G', 877: 'G', 829: 'G', 1904: 'G', 1512: 'G', 403: 'G', 1687: 'G', 352: 'G', 1959: 'G', 1313: 'G', 1136: 'G', 85: 'G', 896: 'G', 1195: 'G', 1867: 'G', 130: 'G', 342: 'G', 667: 'G', 743: 'G', 21: 'G', 1796: 'G', 814: 'G', 1321: 'G', 1890: 'G', 1643: 'G', 1405: 'G', 1964: 'G', 516: 'G', 1410: 'G', 1331: 'G', 568: 'G', 1730: 'G', 32: 'G', 1046: 'G', 116: 'G', 1988: 'G', 602: 'G', 1019: 'G', 1757: 'G', 1148: 'G', 1668: 'G', 974: 'G', 618: 'G', 39: 'G', 681: 'G', 1471: 'G', 567: 'G', 912: 'G', 990: 'G', 156: 'G', 174: 'G', 1006: 'G', 347: 'G', 1578: 'G', 333: 'G', 1112: 'G', 1017: 'G', 160: 'G', 56: 'G', 1183: 'E', 1060: 'E', 967: 'E', 1483: 'E', 410: 'E', 1305: 'E', 792: 'E', 1980: 'E', 1040: 'E', 213: 'E', 1876: 'E', 705: 'E', 1965: 'E', 1640: 'E', 612: 'E', 1079: 'E', 1139: 'E', 1542: 'E', 876: 'E', 392: 'E', 1443: 'E', 49: 'E', 1636: 'E', 142: 'E', 649: 'E', 540: 'E', 1349: 'E', 1737: 'E', 1639: 'E', 1209: 'E', 861: 'E', 1280: 'E', 1503: 'E', 6: 'E', 1230: 'E', 1262: 'E', 331: 'E', 503: 'E', 1284: 'E', 841: 'E', 1550: 'E', 581: 'E', 1973: 'E', 1707: 'E', 472: 'E', 1822: 'E', 1137: 'E', 1122: 'E', 592: 'E', 453: 'E', 1579: 'E', 1187: 'E', 1275: 'E', 871: 'E', 816: 'E', 599: 'E', 627: 'E', 745: 'E', 732: 'E', 378: 'E', 1170: 'E', 1598: 'E', 598: 'E', 1773: 'E', 878: 'E', 1273: 'E', 268: 'E', 758: 'E', 813: 'E', 1265: 'E', 725: 'E', 1810: 'E', 1442: 'E', 1445: 'E', 1376: 'E', 1626: 'E', 1374: 'E', 753: 'E', 1432: 'E', 1869: 'E', 1274: 'E', 308: 'E', 969: 'E', 608: 'E', 1731: 'E', 788: 'E', 322: 'H', 1261: 'H', 366: 'H', 1714: 'H', 1674: 'H', 1359: 'H', 1360: 'H', 1010: 'H', 429: 'H', 625: 'H', 195: 'H', 657: 'H', 1575: 'H', 1312: 'H', 418: 'H', 1194: 'H', 1698: 'H', 1111: 'H', 686: 'H', 715: 'H', 123: 'H', 1887: 'H', 1891: 'H', 1811: 'H', 918: 'H', 1425: 'H', 1783: 'H', 433: 'H', 1074: 'H', 305: 'H', 57: 'H', 1954: 'H', 770: 'H', 1449: 'H', 1298: 'H', 1935: 'H', 1178: 'H', 1499: 'H', 411: 'H', 242: 'H', 1983: 'H', 245: 'H', 1204: 'H', 1036: 'H', 1351: 'H', 702: 'H', 562: 'H', 1091: 'H', 693: 'H', 210: 'H', 1971: 'H', 220: 'H', 574: 'H', 1994: 'H', 18: 'H', 1385: 'H', 1913: 'H', 1191: 'H', 1044: 'H', 260: 'H', 774: 'H', 865: 'H', 1524: 'H', 564: 'H', 978: 'H', 639: 'H', 748: 'H', 1630: 'H', 537: 'H', 1989: 'H', 293: 'H', 1304: 'H', 931: 'H', 1725: 'H', 405: 'H', 950: 'H', 1389: 'H', 1027: 'H', 229: 'H', 1526: 'H', 306: 'H', 583: 'H', 258: 'H', 1609: 'I', 1134: 'I', 1765: 'I', 419: 'I', 1378: 'I', 1004: 'I', 1984: 'I', 1769: 'I', 1056: 'I', 341: 'I', 947: 'I', 1786: 'I', 828: 'I', 78: 'I', 1382: 'I', 605: 'I', 1366: 'I', 381: 'I', 1323: 'I', 1317: 'I', 647: 'I', 695: 'I', 1042: 'I', 1858: 'I', 510: 'I', 1728: 'I', 679: 'I', 1482: 'I', 1227: 'I', 205: 'I', 1412: 'I', 222: 'I', 1424: 'I', 1549: 'I', 984: 'I', 863: 'I', 317: 'I', 132: 'I', 104: 'I', 1792: 'I', 1780: 'I', 1925: 'I', 48: 'I', 29: 'I', 1921: 'I', 284: 'I', 956: 'I', 1898: 'I', 1722: 'I', 1791: 'I', 1982: 'I', 1092: 'I', 1184: 'I', 64: 'I', 1103: 'I', 1065: 'I', 434: 'I', 624: 'I', 1834: 'I', 1447: 'I', 1762: 'I', 1893: 'I', 907: 'I', 1557: 'I', 416: 'I', 645: 'I', 964: 'I', 1464: 'I', 425: 'I', 1480: 'I', 1418: 'I', 1080: 'I', 1099: 'I', 157: 'I', 112: 'I', 544: 'I', 1073: 'C', 701: 'C', 860: 'C', 272: 'C', 614: 'C', 1243: 'C', 422: 'C', 1836: 'C', 1058: 'C', 344: 'C', 1631: 'C', 1861: 'C', 1428: 'C', 363: 'C', 995: 'C', 1322: 'C', 842: 'C', 894: 'C', 1805: 'C', 376: 'C', 184: 'C', 1453: 'C', 482: 'C', 913: 'C', 1343: 'C', 515: 'C', 940: 'C', 1242: 'C', 1582: 'C', 389: 'C', 1670: 'C', 656: 'C', 1634: 'C', 1396: 'C', 804: 'C', 1224: 'C', 1826: 'C', 473: 'C', 880: 'C', 1416: 'C', 900: 'C', 1701: 'C', 1717: 'C', 1130: 'C', 1260: 'C', 1812: 'C', 1303: 'C', 383: 'C', 757: 'C', 189: 'C', 24: 'C', 345: 'C', 520: 'C', 848: 'C', 1929: 'C', 298: 'C', 1318: 'C', 559: 'C', 1819: 'C', 315: 'C', 584: 'C', 1540: 'C', 1798: 'C', 941: 'C', 1345: 'C', 1192: 'C', 619: 'C', 1662: 'C', 152: 'C', 449: 'C', 1572: 'C', 922: 'C', 40: 'C', 1743: 'C', 966: 'C', 902: 'C', 1763: 'C', 535: 'C', 223: 'C', 42: 'C', 1573: 'C', 1779: 'C', 1886: 'C', 465: 'C', 1653: 'C', 318: 'C', 309: 'C', 1282: 'C', 1838: 'C', 930: 'C', 1350: 'C', 794: 'C', 920: 'C', 993: 'C', 88: 'F', 825: 'F', 485: 'F', 41: 'F', 1704: 'F', 1201: 'F', 1879: 'F', 1561: 'F', 450: 'F', 1885: 'F', 1736: 'F', 874: 'F', 62: 'F', 578: 'F', 1348: 'F', 275: 'F', 151: 'F', 1172: 'F', 1244: 'F', 1081: 'F', 1724: 'F', 1768: 'F', 731: 'F', 898: 'F', 832: 'F', 934: 'F', 122: 'F', 1975: 'F', 784: 'F', 1915: 'F', 524: 'F', 1422: 'F', 1841: 'F', 1837: 'F', 486: 'F', 1411: 'F', 1001: 'F', 215: 'F', 1169: 'F', 925: 'F', 826: 'F', 273: 'F', 1479: 'F', 772: 'F', 80: 'F', 1052: 'F', 1587: 'F', 1308: 'F', 397: 'F', 1035: 'F', 1403: 'F', 234: 'F', 218: 'F', 1554: 'F', 1316: 'F', 891: 'F', 5: 'F', 1916: 'F', 239: 'F', 1461: 'F', 226: 'F', 288: 'F', 353: 'F', 780: 'F', 1764: 'F', 22: 'F', 1776: 'F', 1651: 'F', 1296: 'F', 965: 'F', 1569: 'F', 805: 'F', 1176: 'F', 1077: 'F', 588: 'F', 1086: 'F', 1947: 'F', 1546: 'F', 951: 'F', 367: 'F', 1774: 'F', 942: 'F', 302: 'F', 181: 'D', 1501: 'D', 176: 'D', 1279: 'D', 336: 'D', 99: 'D', 1739: 'D', 1702: 'D', 103: 'D', 664: 'D', 802: 'D', 718: 'D', 890: 'D', 810: 'D', 1658: 'D', 1240: 'D', 1164: 'D', 1734: 'D', 542: 'D', 1544: 'D', 1390: 'D', 1219: 'D', 728: 'D', 1388: 'D', 460: 'D', 371: 'D', 269: 'D', 771: 'D', 36: 'D', 504: 'D', 506: 'D', 1759: 'D', 1507: 'D', 650: 'D', 1566: 'D', 1688: 'D', 603: 'D', 1860: 'D', 1270: 'D', 55: 'D', 221: 'D', 1158: 'D', 423: 'D', 447: 'D', 198: 'D', 101: 'D', 1691: 'D', 1522: 'D', 1162: 'D', 1426: 'D', 666: 'D', 1329: 'D', 521: 'D', 621: 'D', 1347: 'D', 1301: 'D', 833: 'D', 414: 'D', 791: 'D', 494: 'D', 1613: 'D', 140: 'D', 1095: 'D', 1125: 'D', 1166: 'D', 1185: 'D', 167: 'D', 857: 'D', 27: 'D', 1785: 'D', 613: 'D', 458: 'D', 1026: 'D', 348: 'D', 1818: 'D', 270: 'D', 1944: 'D', 468: 'D', 683: 'D', 855: 'D', 1586: 'D', 669: 'D', 927: 'D', 1750: 'D', 795: 'D', 264: 'D', 1062: 'D'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_skills_sorted is already defined and loaded\n",
    "\n",
    "# Initialize a dictionary to hold the worker allocations\n",
    "print(df_skills_sorted.columns)\n",
    "worker_allocations = {}\n",
    "\n",
    "# Iterate through each skill in the sorted DataFrame\n",
    "for index, row in df_skills_sorted.iterrows():\n",
    "    skill_req = row['skill']\n",
    "    percentage = row['Percentage']\n",
    "    site_id = row['Job Site ID']\n",
    "    skill_rank_df = pd.read_csv(f'ranks/{skill_req}/skill_rank.csv')\n",
    "\n",
    "    num_workers_needed = int((percentage / 100) * len(skill_rank_df))\n",
    "\n",
    "    allocated_workers = 0\n",
    "    for _, worker_row in skill_rank_df.iterrows():\n",
    "        worker_id = worker_row['worker_id']  # Adjust based on the actual column name in skill_rank_df\n",
    "\n",
    "        # Check if the worker is already allocated (in any site)\n",
    "        if worker_id not in [worker for site_workers in worker_allocations.values() for worker in site_workers]:\n",
    "            # Allocate the worker to the current site\n",
    "            if site_id not in worker_allocations:\n",
    "                worker_allocations[site_id] = []\n",
    "            worker_allocations[site_id].append(worker_id)\n",
    "            allocated_workers += 1\n",
    "\n",
    "            # Break the loop if the required number of workers has been allocated\n",
    "            if allocated_workers >= num_workers_needed:\n",
    "                break\n",
    "\n",
    "# print(worker_allocations)\n",
    "worker_to_job_site = {worker_id: site_id for site_id, workers in worker_allocations.items() for worker_id in workers}\n",
    "\n",
    "print(worker_to_job_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(list(worker_to_job_site.items()), columns=['worker_id', 'job_site'])\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('map.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_764/4072989052.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['job_site'] = df_filtered['worker_id'].map(worker_to_job_site).fillna('NULL')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('generated_workers.csv')\n",
    "\n",
    "# Filter rows with availability as \"Available\"\n",
    "df_filtered = df[df['availability'] == 'Available']\n",
    "df_filtered['job_site'] = df_filtered['worker_id'].map(worker_to_job_site).fillna('NULL')\n",
    "\n",
    "# Export the filtered and mapped data to train_data.csv\n",
    "df_filtered.to_csv('train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total required members: 421\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('train_data.csv')\n",
    "\n",
    "# Count the non-NULL values in the \"job_sites\" column\n",
    "total_req_members = df['job_site'].notnull().sum()\n",
    "\n",
    "print(\"Total required members:\", total_req_members)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
